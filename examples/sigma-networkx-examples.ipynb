{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from poitousprint import Portic, Toflit\n",
    "import json\n",
    "import networkx as nx\n",
    "from ipysigma import Sigma\n",
    "\n",
    "portic_client = Portic()\n",
    "toflit_client = Toflit()\n",
    "\n",
    "# this function allows to map a value from a domain of min-max to another\n",
    "def map_value(value, domain_min, domain_max, range_min, range_max):\n",
    "    left_span = domain_max - domain_min\n",
    "    right_span = range_max - range_min\n",
    "\n",
    "    # Convert the left range into a 0-1 range (float)\n",
    "    scaled = float(value - domain_min) / float(left_span)\n",
    "\n",
    "    # Convert the 0-1 range into a value in the right range.\n",
    "    return range_min + (scaled * right_span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naive toflit18 request\n",
    "flows = toflit_client.get_flows(\n",
    "    year=1789,\n",
    "    customs_region='La Rochelle', \n",
    "    params=[\n",
    "      \"product\",\n",
    "      \"partner\",\n",
    "      \"import\",\n",
    "      \"value\",\n",
    "      \"line\",\n",
    "      \"partner_simplification\",\n",
    "      \"customs_office\"\n",
    "\t]\n",
    ")\n",
    "flows[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Étape 1 : première expérimentation\n",
    "\n",
    "Cartographie d'un réseau bipartite entre les produits et les partenaires "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# créer un graphe\n",
    "Graph = nx.Graph()\n",
    "\n",
    "# créer des dict pour les deux types de noeuds et les liens\n",
    "products_uniq = {}\n",
    "partners_uniq = {}\n",
    "edges_uniq = {}\n",
    "# remplir les dicts\n",
    "for flow in flows:\n",
    "    partner = flow[\"partner\"]\n",
    "    product = flow[\"product\"]\n",
    "    partner_id = \"partner_\" + partner\n",
    "    product_id = \"product_\" + product\n",
    "    if product_id in products_uniq:\n",
    "        products_uniq[product_id] = {**products_uniq[product_id], \"size\": products_uniq[product_id][\"size\"] + 1}\n",
    "    else:\n",
    "       products_uniq[product_id] = {\n",
    "           \"type\": \"product\", \n",
    "           \"name\": product, \n",
    "           \"color\": \"rgb(0, 255, 0)\",\n",
    "           \"size\": 1\n",
    "       }\n",
    "    if partner_id in partners_uniq:\n",
    "        partners_uniq[partner_id] = {**partners_uniq[partner_id], \"size\": partners_uniq[partner_id][\"size\"] + 1}\n",
    "    else:\n",
    "       partners_uniq[partner_id] = {\n",
    "           \"type\": \"partner\", \n",
    "           \"name\": partner, \n",
    "           \"color\": \"rgb(255, 0, 0)\",\n",
    "           \"size\": 1\n",
    "       }\n",
    "    edge_footprint = partner_id + \"-\" + product_id\n",
    "    if edge_footprint in edges_uniq:\n",
    "        edges_uniq[edge_footprint][\"weight\"] += 1\n",
    "    else:\n",
    "        edges_uniq[edge_footprint] = {\n",
    "            \"source\": product_id,\n",
    "            \"target\": partner_id,\n",
    "            \"weight\": 1\n",
    "        }\n",
    "# concaténer les deux dicts de noeuds en un seul\n",
    "all_nodes = partners_uniq\n",
    "all_nodes.update(products_uniq)\n",
    "# applatir et formatter les noeuds\n",
    "nodes = []\n",
    "for key, node in all_nodes.items():\n",
    "    nodes.append((key, node))\n",
    "edges = []\n",
    "\n",
    "for key, edge in edges_uniq.items():\n",
    "    edges.append((edge[\"source\"], edge[\"target\"], {\"weight\": edge[\"weight\"]}))\n",
    "    \n",
    "domain_min_nodes_size = min([node[1]['size'] for node in nodes])\n",
    "domain_max_nodes_size = max([node[1]['size'] for node in nodes])\n",
    "range_in_nodes_size = [1, 10]\n",
    "nodes_size_mapping_params = [domain_min_nodes_size, domain_max_nodes_size, *range_in_nodes_size]\n",
    "\n",
    "for node in nodes:\n",
    "    node[1][\"size\"] = map_value(node[1][\"size\"], *nodes_size_mapping_params)\n",
    "    node[1][\"label\"] = node[1][\"name\"]\n",
    "\n",
    "\n",
    "Graph.add_nodes_from(nodes)\n",
    "Graph.add_edges_from(edges)\n",
    "\n",
    "Sigma(Graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Étape 2 : factoriser la fabrication de réseaux de coocurrence\n",
    "\n",
    "On fabrique une fonction générique qui permet de fabriquer un réseau à partir :\n",
    "\n",
    "1. d'une liste de dicts (ex. flux toflit18)\n",
    "1. d'une liste de deux propriétés à comparer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_coocurrences_graph(data, key_1, key_2, params=None):\n",
    "    # créer un graphe\n",
    "    Graph = nx.Graph()\n",
    "\n",
    "    # créer des dict pour les deux types de noeuds et les liens\n",
    "    key1_uniq = {}\n",
    "    key2_uniq = {}\n",
    "    edges_uniq = {}\n",
    "    default_params = {\n",
    "        \"color_1\": \"rgb(0, 255, 0)\",\n",
    "        \"color_2\": \"rgb(255, 0, 0)\",\n",
    "        \"node_min_size\": 1,\n",
    "        \"node_max_size\": 10\n",
    "    }\n",
    "    final_params = default_params\n",
    "    if params is not None :\n",
    "        final_params = {\n",
    "            *default_params,\n",
    "            *params\n",
    "        }\n",
    "    \n",
    "    # remplir les dicts\n",
    "    for datum in data:\n",
    "        if key_1 in datum and key_2 in datum:\n",
    "            value_1 = datum[key_1] if datum[key_1] is not None else \"undefined\"\n",
    "            value_2 = datum[key_2] if datum[key_2] is not None else \"undefined\"\n",
    "            value_1_id = key_1 + \"_\" + value_1\n",
    "            value_2_id = key_2 + \"_\" + value_2\n",
    "            if value_1_id in key1_uniq:\n",
    "                key1_uniq[value_1_id] = {**key1_uniq[value_1_id], \"size\": key1_uniq[value_1_id][\"size\"] + 1}\n",
    "            else:\n",
    "               key1_uniq[value_1_id] = {\n",
    "                   \"type\": key_1, \n",
    "                   \"name\": value_1, \n",
    "                   \"color\": final_params[\"color_1\"],\n",
    "                   \"size\": 1\n",
    "               }\n",
    "            if value_2_id in key2_uniq:\n",
    "                key2_uniq[value_2_id] = {**key2_uniq[value_2_id], \"size\": key2_uniq[value_2_id][\"size\"] + 1}\n",
    "            else:\n",
    "               key2_uniq[value_2_id] = {\n",
    "                   \"type\": key_2, \n",
    "                   \"name\": value_2, \n",
    "                   \"color\": final_params[\"color_2\"],\n",
    "                   \"size\": 1\n",
    "               }\n",
    "            edge_footprint = value_1_id + \"-\" + value_2_id\n",
    "            if edge_footprint in edges_uniq:\n",
    "                edges_uniq[edge_footprint][\"weight\"] += 1\n",
    "            else:\n",
    "                edges_uniq[edge_footprint] = {\n",
    "                    \"source\": value_1_id,\n",
    "                    \"target\": value_2_id,\n",
    "                    \"weight\": 1\n",
    "                }\n",
    "    # concaténer les deux dicts de noeuds en un seul\n",
    "    all_nodes = key1_uniq\n",
    "    all_nodes.update(key2_uniq)\n",
    "    # applatir et formatter les noeuds\n",
    "    nodes = []\n",
    "    for key, node in all_nodes.items():\n",
    "        nodes.append((key, node))\n",
    "    edges = []\n",
    "\n",
    "    for key, edge in edges_uniq.items():\n",
    "        edges.append((edge[\"source\"], edge[\"target\"], {\"weight\": edge[\"weight\"]}))\n",
    "        \n",
    "    # ajuster la taille des noeuds en fonction d'un min et d'un max donnés\n",
    "    domain_min_nodes_size = min([node[1]['size'] for node in nodes])\n",
    "    domain_max_nodes_size = max([node[1]['size'] for node in nodes])\n",
    "    range_in_nodes_size = [final_params[\"node_min_size\"], final_params[\"node_max_size\"]]\n",
    "    nodes_size_mapping_params = [domain_min_nodes_size, domain_max_nodes_size, *range_in_nodes_size]\n",
    "\n",
    "    for node in nodes:\n",
    "        node[1][\"size\"] = map_value(node[1][\"size\"], *nodes_size_mapping_params)\n",
    "        node[1][\"label\"] = node[1][\"name\"]\n",
    "\n",
    "\n",
    "    Graph.add_nodes_from(nodes)\n",
    "    Graph.add_edges_from(edges)\n",
    "\n",
    "    return Sigma(Graph, start_layout=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_coocurrences_graph(flows, \"product\", \"partner_simplification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_coocurrences_graph(flows, \"partner\", \"partner_simplification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Étape 3 : test avec PORTIC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flows = portic_client.get_flows(year=1789)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flows[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(flows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_coocurrences_graph(flows, \"departure_fr\", \"destination_fr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_coocurrences_graph(flows, \"homeport_toponyme_fr\", \"destination_fr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Étape 4 : test des croisements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_flow_partner(flow):\n",
    "    res = flow.copy()\n",
    "    partner = flow['destination_partner_balance_1789']\n",
    "    if flow is None and 'destination_partner_balance_supp_1789' in flow:\n",
    "        partner = flow['destination_partner_balance_supp_1789']\n",
    "    if flow is None:\n",
    "        partner = 'non attribué'\n",
    "    res['partner'] = partner\n",
    "    return res\n",
    "    \n",
    "flows_with_toflit18_partner = [resolve_flow_partner(flow) for flow in flows if flow[\"source_subset\"] == \"Poitou_1789\"]\n",
    "\n",
    "render_coocurrences_graph(flows_with_toflit18_partner, \"departure\", \"partner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_partners = set([t[\"partner\"] for t in flows_with_toflit18_partner])\n",
    "unique_partners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test sans la france\n",
    "flows_with_toflit18_partner=[flow for flow in flows_with_toflit18_partner if flow[\"partner\"] != \"France\" and flow[\"partner\"] is not None]\n",
    "render_coocurrences_graph(flows_with_toflit18_partner, \"departure\", \"partner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
