{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Croisement 1 - Croisement produits\n",
    "\n",
    "Objectif : \n",
    "Pour les produit commercés / transportés pour les flux concernant le datasprint, obtenir 3 ensembles :\n",
    "- ensemble 1 - produits qu'on retrouve à la fois dans Toflit18 et Portic\n",
    "- ensemble 2 - produits qu'on retrouve exclusivement dans Toflit18\n",
    "- ensemble 3 - produits qu'on retrouve exclusivement dans Portic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from poitousprint import Portic, Toflit, get_pointcalls_commodity_purposes_as_toflit_product\n",
    "\n",
    "toflit_client = Toflit()\n",
    "portic_client = Portic()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choix d'une classification d'alignement\n",
    "chosen_classification = 'product_revolutionempire'\n",
    "# exemples d'autres classifications possibles : product_source', 'product_orthographic', 'product_simplification'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# récupération des pointcalls Portic qui concernent le datasprint\n",
    "pointcalls_datasprint = portic_client.get_pointcalls(\n",
    " source_subset = 'Poitou_1789'\n",
    ")\n",
    "\n",
    "# enrichissement de ces pointcalls avec la propriété 'commodity_as_toflit' qui nous donne l'équivalent des produits navigo dans Toflit18 avec la classification choisie\n",
    "croisement_produits = get_pointcalls_commodity_purposes_as_toflit_product(pointcalls_datasprint, product_classification=chosen_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "navigo_products_for_datasprint = set()\n",
    "for pointcall in croisement_produits:\n",
    "    if pointcall['commodity_purposes'] is not None:\n",
    "        for commodity in pointcall['commodity_purposes']:\n",
    "            navigo_products_for_datasprint.add(commodity['commodity_as_toflit'])\n",
    "\n",
    "navigo_products_for_datasprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# récupération des flows Toflit18 qui concernent le datasprint\n",
    "flows = toflit_client.get_flows(\n",
    "    year=1789, \n",
    "    customs_region='La Rochelle',\n",
    ")\n",
    "\n",
    "toflit_products_for_datasprint = set()\n",
    "for flow in flows:\n",
    "    toflit_products_for_datasprint.add(flow[chosen_classification])\n",
    "\n",
    "toflit_products_for_datasprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = toflit_products_for_datasprint.intersection(navigo_products_for_datasprint)\n",
    "\n",
    "result2 = toflit_products_for_datasprint.difference(navigo_products_for_datasprint)\n",
    "\n",
    "result3 = navigo_products_for_datasprint.difference(toflit_products_for_datasprint)\n",
    "\n",
    "print(\"ensemble 1 - produits qu'on retrouve à la fois dans Toflit18 et Portic :\\n\", result1)\n",
    "print(\"\\n\\nensemble 2 - produits qu'on retrouve exclusivement dans Toflit18 : \\n\", result2)\n",
    "print(\"\\n\\nensemble 3 - produits qu'on retrouve exclusivement dans Portic : \\n\", result3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# écriture dans un fichier txt\n",
    "\n",
    "# write data in a file.\n",
    "fichier_texte = open('dumps/croisement_produits_datasprint_' + chosen_classification + '.txt',\"w\")\n",
    "  \n",
    "# \\n is placed to indicate EOL (End of Line)\n",
    "fichier_texte.write(\"ensemble 1 - produits qu'on retrouve à la fois dans Toflit18 et Portic :\\n\") \n",
    "for produit in result1:\n",
    "    fichier_texte.write(str(produit)+\"\\n\")\n",
    "\n",
    "fichier_texte.write(\"\\n\\n\\nensemble 2 - produits qu'on retrouve exclusivement dans Toflit18 :\\n\") \n",
    "for produit in result2:\n",
    "    fichier_texte.write(str(produit)+\"\\n\")\n",
    "\n",
    "fichier_texte.write(\"\\n\\n\\nensemble 3 - produits qu'on retrouve exclusivement dans Portic :\\n\") \n",
    "for produit in result3:\n",
    "    fichier_texte.write(str(produit)+\"\\n\")\n",
    "\n",
    "fichier_texte.close() #to change file access modes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Croisement 2 - Croisement ports / bureaux des Fermes\n",
    "\n",
    "### Objectif : Représenter l'intersection et l'exclusion des ports Navigo avec les bureaux des Fermes Toflit\n",
    "\n",
    "- grosseur des liens dépend du nombre de pointcalls concernés\n",
    "- colorer de la même manière tous les ports rattachés à un même bureau des Fermes\n",
    "\n",
    "=> diagramme alluvial avec RAWGraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from poitousprint import Portic, Toflit, get_pointcalls_commodity_purposes_as_toflit_product\n",
    "\n",
    "toflit_client = Toflit()\n",
    "portic_client = Portic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# récupération de tous les ports navigo concernés\n",
    "\n",
    "pointcalls_datasprint = portic_client.get_pointcalls(\n",
    " year = 1789,\n",
    " pointcall_admiralty = ['La Rochelle', 'Marennes', 'Sables d\\'Olonne'],\n",
    " # si on utilise source_subset = 'Poitou_1789' on aura des ports qui ne correspondent pas à la direction des Fermes de La Rochelle => trop de ports (invisualisable)\n",
    " params = ['pointcall', 'ferme_bureau', 'pointcall_admiralty', 'source_subset']\n",
    ")\n",
    "\n",
    "pointcalls_datasprint[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# écriture des croisements dans un csv pour nourrir RAWGraphs\n",
    "import csv\n",
    "from csv import DictWriter\n",
    "\n",
    "# tableau qui contient une ligne par pointcall (avec à chaque fois le port Navigo qui correspond à un bureau Toflit) \n",
    "with open('dumps/croisement_ports_bureaux_datasprint.csv', 'w', newline='') as csvfile:\n",
    "        fieldnames = ['port_Navigo','ferme_bureau_Toflit']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()\n",
    "        for pointcall in pointcalls_datasprint:\n",
    "            \n",
    "            # remplacer par \"pas de bureau rattaché\" plutot que None quand le port n'a pas de bureau des Fermes associé\n",
    "            bureau = pointcall['ferme_bureau']\n",
    "            if bureau is None:\n",
    "                bureau = \"pas de bureau rattaché\"\n",
    "            writer.writerow({\n",
    "                'port_Navigo':pointcall['pointcall'],\n",
    "                'ferme_bureau_Toflit':bureau\n",
    "            })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correspondance entre bureaux des Fermes Toflit et ports Navigo - Diagramme alluvial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import SVG\n",
    "SVG(filename='dumps/visualisations/croisement ports Portic : bureaux des Fermes Navigo - datasprint PORTIC 2021/diagramme_alluvial_ports_bureaux.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Croisement 3 - Croisement ports / partenaires commerciaux \n",
    "\n",
    "### Objectif : obtenir un diagramme alluvial qui représente le croisement entre ports Navigo dans lesquels on a des pointcalls 'In' (ce qu'on pourrait analyser comme des destinataires d'exports) et les partenaires commerciaux Toflit18 pour les flux concernant le sprint\n",
    "\n",
    "=> RAWGraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from poitousprint import Portic, Toflit, get_pointcalls_port_as_toflit_partner\n",
    "\n",
    "toflit_client = Toflit()\n",
    "portic_client = Portic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_pointcall_actions = 'In'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# récupération de tous les ports navigo concernés\n",
    "\n",
    "pointcalls_datasprint = portic_client.get_pointcalls(\n",
    " source_subset = 'Poitou_1789',\n",
    " pointcall_action = chosen_pointcall_actions\n",
    ")\n",
    "\n",
    "croisement_partners = get_pointcalls_port_as_toflit_partner(pointcalls_datasprint, 'partner_grouping')\n",
    "print(croisement_partners[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# écriture des alignements dans un dict avec une ligne par match pour grossir les liens selon quantité de pointcalls concernés dans le diagramme alluvial\n",
    "ports_navigo = []\n",
    "\n",
    "for pointcall in croisement_partners: \n",
    "    # remplacer par \"pas de partenaire commercial rattaché\" plutot que None quand le port Navigo ne correspond pas à un partenaire Toflit18\n",
    "    partner = pointcall['pointcall_as_toflit_partner']\n",
    "    if partner is None:\n",
    "        partner = \"pas de partenaire commercial rattaché\"\n",
    "        \n",
    "    ports_navigo.append({\n",
    "        'port_navigo': pointcall['pointcall'],\n",
    "        'toflit_partner':partner\n",
    "    })\n",
    "\n",
    "ports_navigo[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# écriture dans un csv\n",
    "import csv\n",
    "from csv import DictWriter\n",
    "\n",
    "# tableau qui contient une colonne par clé de dict \n",
    "with open('dumps/croisement_ports_' + str(chosen_pointcall_actions) + '_partners_datasprint.csv', 'w', newline='') as csvfile:\n",
    "        fieldnames = ['port_navigo','toflit_partner']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()\n",
    "        for pointcall in ports_navigo:\n",
    "            writer.writerow(pointcall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rattachement des destinataires des \"exports\" de marchandise Navigo à une classification de partenaires commerciaux Toflit - Diagramme alluvial \n",
    "Remarque : Ici, les ports navigo considérés destinataires d'exports sont ceux associés avec un pointcall \"In\" faisant partie des pointcalls du sprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import SVG\n",
    "SVG(filename='dumps/visualisations/croisement ports Portic : bureaux des Fermes Navigo - datasprint PORTIC 2021/diagramme_alluvial_ports_partners.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enquête Navigo\n",
    "\n",
    "#### Objectif : visualisation des données disponibles et avoir une première vue d'ensemble\n",
    "- réseaux bipartites departs / destinations\n",
    "- réseaux monopartites entre ports\n",
    "=> on peut colorer ces réseaux pour identifier les ports concernés par le sprint, ou bien filtrer les données pour ne construire que les noeuds et liens du réseau qui concernent le sprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from poitousprint import Portic, Toflit, get_pointcalls_port_as_toflit_partner, get_flows_or_travels_port_as_toflit_partner\n",
    "import json\n",
    "import networkx as nx\n",
    "from ipysigma import Sigma\n",
    "\n",
    "portic_client = Portic()\n",
    "toflit_client = Toflit()\n",
    "\n",
    "# this function allows to map a value from a domain of min-max to another\n",
    "def map_value(value, domain_min, domain_max, range_min, range_max):\n",
    "    left_span = domain_max - domain_min\n",
    "    right_span = range_max - range_min\n",
    "\n",
    "    # Convert the left range into a 0-1 range (float)\n",
    "    scaled = float(value - domain_min) / float(left_span)\n",
    "\n",
    "    # Convert the 0-1 range into a value in the right range.\n",
    "    return range_min + (scaled * right_span)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonctions génériques qui permettent de fabriquer des réseaux bipartite et monopartite à partir :\n",
    "\n",
    "1. d'une liste de dicts (ex. flux toflit18)\n",
    "2. d'une liste de deux propriétés à comparer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_coocurrences_graph(data, key_1, key_2, params=None):\n",
    "    # créer un graphe\n",
    "    Graph = nx.Graph()\n",
    "\n",
    "    # créer des dict pour les deux types de noeuds et les liens\n",
    "    key1_uniq = {}\n",
    "    key2_uniq = {}\n",
    "    edges_uniq = {}\n",
    "    default_params = {\n",
    "        \"color_1\": \"rgb(0, 255, 0)\", # noeuds de type 1 en vert\n",
    "        \"color_2\": \"rgb(255, 0, 0)\", # noeuds de type 2 en rouge\n",
    "        \"node_min_size\": 1,\n",
    "        \"node_max_size\": 10\n",
    "    }\n",
    "    final_params = default_params\n",
    "    if params is not None :\n",
    "        final_params = {\n",
    "            *default_params,\n",
    "            *params\n",
    "        }\n",
    "    \n",
    "    # remplir les dicts\n",
    "    for datum in data:\n",
    "        if key_1 in datum and key_2 in datum:\n",
    "            value_1 = datum[key_1] if datum[key_1] is not None else \"undefined\"\n",
    "            value_2 = datum[key_2] if datum[key_2] is not None else \"undefined\"\n",
    "            value_1_id = key_1 + \"_\" + value_1\n",
    "            value_2_id = key_2 + \"_\" + value_2\n",
    "            if value_1_id in key1_uniq:\n",
    "                key1_uniq[value_1_id] = {**key1_uniq[value_1_id], \"size\": key1_uniq[value_1_id][\"size\"] + 1}\n",
    "            else:\n",
    "               key1_uniq[value_1_id] = {\n",
    "                   \"type\": key_1, \n",
    "                   \"name\": value_1, \n",
    "                   \"color\": final_params[\"color_1\"],\n",
    "                   \"size\": 1\n",
    "               }\n",
    "            if value_2_id in key2_uniq:\n",
    "                key2_uniq[value_2_id] = {**key2_uniq[value_2_id], \"size\": key2_uniq[value_2_id][\"size\"] + 1}\n",
    "            else:\n",
    "               key2_uniq[value_2_id] = {\n",
    "                   \"type\": key_2, \n",
    "                   \"name\": value_2, \n",
    "                   \"color\": final_params[\"color_2\"],\n",
    "                   \"size\": 1\n",
    "               }\n",
    "            edge_footprint = value_1_id + \"-\" + value_2_id\n",
    "            if edge_footprint in edges_uniq:\n",
    "                edges_uniq[edge_footprint][\"weight\"] += 1\n",
    "            else:\n",
    "                edges_uniq[edge_footprint] = {\n",
    "                    \"source\": value_1_id,\n",
    "                    \"target\": value_2_id,\n",
    "                    \"weight\": 1\n",
    "                }\n",
    "    # concaténer les deux dicts de noeuds en un seul\n",
    "    all_nodes = key1_uniq\n",
    "    all_nodes.update(key2_uniq)\n",
    "    # applatir et formatter les noeuds\n",
    "    nodes = []\n",
    "    for key, node in all_nodes.items():\n",
    "        nodes.append((key, node))\n",
    "    edges = []\n",
    "\n",
    "    for key, edge in edges_uniq.items():\n",
    "        edges.append((edge[\"source\"], edge[\"target\"], {\"weight\": edge[\"weight\"]}))\n",
    "        \n",
    "    # ajuster la taille des noeuds en fonction d'un min et d'un max donnés\n",
    "    domain_min_nodes_size = min([node[1]['size'] for node in nodes])\n",
    "    domain_max_nodes_size = max([node[1]['size'] for node in nodes])\n",
    "    range_in_nodes_size = [final_params[\"node_min_size\"], final_params[\"node_max_size\"]]\n",
    "    nodes_size_mapping_params = [domain_min_nodes_size, domain_max_nodes_size, *range_in_nodes_size]\n",
    "\n",
    "    for node in nodes:\n",
    "        node[1][\"size\"] = map_value(node[1][\"size\"], *nodes_size_mapping_params)\n",
    "        node[1][\"label\"] = node[1][\"name\"]\n",
    "        if node[1][\"label\"] == 'undefined':\n",
    "            node[1][\"label\"] = 'Non défini'\n",
    "\n",
    "\n",
    "    Graph.add_nodes_from(nodes)\n",
    "    Graph.add_edges_from(edges)\n",
    "\n",
    "    return Sigma(Graph, start_layout=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_monopartite_graph_port_exchanges(data, key_1, key_2, params=None): # data could be Navigo flows or travels \n",
    "\n",
    "    # créer un graphe\n",
    "    Graph = nx.Graph()\n",
    "\n",
    "    # créer des dict pour l'unique type de noeuds et les liens\n",
    "    key_uniq = {}\n",
    "    edges_uniq = {}\n",
    "    default_params = {\n",
    "        \"color_1\": \"rgb(0, 255, 0)\", # noeuds de type 1 en vert\n",
    "        \"color_2\": \"rgb(255, 0, 0)\", # noeuds de type 2 en rouge\n",
    "        \"node_min_size\": 1,\n",
    "        \"node_max_size\": 10\n",
    "    }\n",
    "    final_params = default_params\n",
    "    if params is not None :\n",
    "        final_params = {\n",
    "            *default_params,\n",
    "            *params\n",
    "        }\n",
    "        \n",
    "    # remplir les dicts\n",
    "    for datum in data:\n",
    "        if key_1 in datum and key_2 in datum:\n",
    "            value_1 = datum[key_1] if datum[key_1] is not None else \"undefined\"\n",
    "            value_2 = datum[key_2] if datum[key_2] is not None else \"undefined\"\n",
    "            value_1_id = value_1_id = key_1 + \"_\" + value_1\n",
    "            value_2_id = key_2 + \"_\" + value_2\n",
    "\n",
    "            if value_1_id in key_uniq:\n",
    "                key_uniq[value_1_id] = {**key_uniq[value_1_id], \"size\": key_uniq[value_1_id][\"size\"] + 1}\n",
    "            else:\n",
    "               key_uniq[value_1_id] = {\n",
    "                   \"type\": key_1, \n",
    "                   \"label\": value_1, \n",
    "                   \"color\": \"rgb(0, 255, 0)\",\n",
    "                   \"size\": 1\n",
    "               }\n",
    "\n",
    "            if value_2_id in key_uniq:\n",
    "                key_uniq[value_2_id] = {**key_uniq[value_2_id], \"size\": key_uniq[value_2_id][\"size\"] + 1}\n",
    "            else:\n",
    "               key_uniq[value_2_id] = {\n",
    "                   \"type\": key_2, \n",
    "                   \"label\": value_2, \n",
    "                   \"color\": \"rgb(0, 255, 0)\",\n",
    "                   \"size\": 1\n",
    "               }\n",
    "\n",
    "            edge_footprint = value_1_id + \"-\" + value_2_id\n",
    "\n",
    "            if edge_footprint in edges_uniq:\n",
    "                edges_uniq[edge_footprint][\"weight\"] += 1\n",
    "            else:\n",
    "                edges_uniq[edge_footprint] = {\n",
    "                    \"source\": value_1_id,\n",
    "                    \"target\": value_2_id,\n",
    "                    \"weight\": 1\n",
    "                }\n",
    "    \n",
    "    \n",
    "    # concaténer les deux dicts de noeuds en un seul => obsolète dans ce cas\n",
    "    all_nodes = key_uniq\n",
    "    # all_nodes.update(# autre dict de noeuds )\n",
    "\n",
    "    # applatir et formatter les noeuds\n",
    "    nodes = []\n",
    "    for key, node in all_nodes.items():\n",
    "        nodes.append((key, node))\n",
    "    edges = []\n",
    "\n",
    "    for key, edge in edges_uniq.items():\n",
    "        edges.append((edge[\"source\"], edge[\"target\"], {\"weight\": edge[\"weight\"]}))\n",
    "\n",
    "    domain_min_nodes_size = min([node[1]['size'] for node in nodes])\n",
    "    domain_max_nodes_size = max([node[1]['size'] for node in nodes])\n",
    "    range_in_nodes_size = [1, 10]\n",
    "    nodes_size_mapping_params = [domain_min_nodes_size, domain_max_nodes_size, *range_in_nodes_size]\n",
    "\n",
    "    for node in nodes:\n",
    "        node[1][\"size\"] = map_value(node[1][\"size\"], *nodes_size_mapping_params)\n",
    "        # node[1][\"label\"] = node[1][\"name\"]\n",
    "    \n",
    "    Graph.add_nodes_from(nodes)\n",
    "    Graph.add_edges_from(edges)\n",
    "\n",
    "    return Sigma(Graph, start_layout=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Je vais chercher les pointcalls / flows / travels du sprint (côté Navigo) pour nourrir mes réseaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointcalls_datasprint = portic_client.get_pointcalls(\n",
    "    source_subset = 'Poitou_1789')\n",
    "\n",
    "pointcalls_with_toflit_partners = get_pointcalls_port_as_toflit_partner(pointcalls_datasprint, 'partner_grouping')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointcalls_with_toflit_partners[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pointcalls_datasprint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flows_datasprint = portic_client.get_flows(\n",
    "        ports = ['A1964694', # je fonctionne avec tous les UHGS_id des ports associés à la direction des fermes de La Rochelle (voir fichier aligenement localités dans le drive : Noirmoutier et Ile de Bouin sont pris en compte)\n",
    "                'A0171758',\n",
    "                'A0136930',\n",
    "                'A0196496',\n",
    "                'A0198999',\n",
    "                'A0137148',\n",
    "                'A0127055',\n",
    "                'A0133403',\n",
    "                'A0213721',\n",
    "                'A0199508',\n",
    "                'A0148208',\n",
    "                'A0141325',\n",
    "                'A0138533',\n",
    "                'A1964982',\n",
    "                'A0186515',\n",
    "                'A0124809',\n",
    "                'A1964767',\n",
    "                'A0172590',\n",
    "                'A0181608',\n",
    "                'A0165077',\n",
    "                'A0169240',\n",
    "                'A0165056',\n",
    "                'A1963997',\n",
    "                'A0136403',\n",
    "                'A0195938',\n",
    "                'A0122971',\n",
    "                'A0207992'], # sinon on devrait pouvoir fonctionner avec source_subset = 'Poitou_1789' mais pour l'instant ne fonctionne pas pour moi\n",
    "    year = 1789)\n",
    "\n",
    "# cette fonction ajoute les attributs \"departure_fr_as_toflit_partner\" et \"destination_fr_as_toflit_partner\" à un flow ou travel navigo (à perfectionner => pour l'instant elle n'associe pas de partenaire aux ports Etrangers du sprint, et ne semble fonctionner que pour la France ...)\n",
    "flows_with_toflit_partners = get_flows_or_travels_port_as_toflit_partner(flows_datasprint, 'partner_grouping')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flows_with_toflit_partners[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(flows_datasprint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travels_datasprint = portic_client.get_travels(source_subset = 'Poitou_1789')\n",
    "\n",
    "travels_with_toflit_partners = get_flows_or_travels_port_as_toflit_partner(travels_datasprint, 'partner_grouping')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travels_with_toflit_partners[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(travels_datasprint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fabrication de réseaux \n",
    "\n",
    "## chaque réseau est construit avec des flows et des travels pour pouvoir comparer les données disponibles sur ces 2 types d'objets Navigo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Fabrication de réseaux bipartites : départ / arrivée\n",
    "\n",
    "#### Si 2 ports font partie du même flow, ou du même travel, ils seront reliés sur le graphe\n",
    "#### Pour chaque réseau on fonctionne d'abord avec les données des flows, puis les données des travels\n",
    "\n",
    "##### Légende :\n",
    "##### - ports de départ en vert\n",
    "##### - ports d'arrivée en rouge\n",
    "\n",
    "Remarques : \n",
    "- Peut-être intéressant de filtrer les ports de départ / d'arrivée sur la direction des Fermes de La Rochelle (pour savoir où vont les bateaux qui partent de la région / d'où viennent les bateaux arrivent dans la région)\n",
    "- Avec les flows risque de duplications\n",
    "- Avec travels on a pas beaucoup de données apparemment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Visualisation de données Navigo pures : réseau port Navigo de départ / port Navigo d'arrivée "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_coocurrences_graph(flows_datasprint, \"departure_fr\", \"destination_fr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_coocurrences_graph(travels_datasprint, \"departure_fr\", \"destination_fr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. croisement : partenaire Toflit de départ / port Navigo d'arrivée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_coocurrences_graph(flows_with_toflit_partners, \"departure_fr_as_toflit_partner\", \"destination_fr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_coocurrences_graph(travels_with_toflit_partners, \"departure_fr_as_toflit_partner\", \"destination_fr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. croisement : port Navigo de départ / bureau des Fermes Toflit d'arrivée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_coocurrences_graph(flows_datasprint, \"departure_fr\", \"destination_ferme_bureau\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_coocurrences_graph(travels_datasprint, \"departure_fr\", \"destination_ferme_bureau\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. croisement (visualisation de données Navigo avec des entités Toflit) : bureau des Fermes Toflit de départ / partenaire Toflit d'arrivée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_coocurrences_graph(flows_with_toflit_partners, \"departure_ferme_bureau\", \"destination_fr_as_toflit_partner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_coocurrences_graph(travels_with_toflit_partners, \"departure_ferme_bureau\", \"destination_fr_as_toflit_partner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fabriction de réseau monopartite : échanges entre ports\n",
    "\n",
    "#### Si 2 ports sont dans le même flow ou travel, ils sont reliés \n",
    "#### Plus les échanges sont intenses, plus les ports sont proches sur le graphe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Visualisation de données Navigo pures : les noeuds sont des ports Navigo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_monopartite_graph_port_exchanges(flows_datasprint, 'departure_fr', 'destination_fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_monopartite_graph_port_exchanges(travels, 'departure_fr', 'destination_fr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. croisement (visualisation de données Navigo avec un angle de vue Toflit) : les noeuds sont des partenaires Toflit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_monopartite_graph_port_exchanges(flows_with_toflit_partners, 'departure_fr_as_toflit_partner', 'destination_fr_as_toflit_partner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_monopartite_graph_port_exchanges(travels_with_toflit_partners, 'departure_fr_as_toflit_partner', 'destination_fr_as_toflit_partner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus : \n",
    "- fonction qui adapte la couleur des noeuds pour qu'on distingue ceux qui font partie du champ d'étude du datasprint / ceux qui n'en font pas partie\n",
    "- fonction qui filtre le \"data\" donner pour n'inclure dans le réseau que les entités qui font partie du champ d'étude du datasprint\n",
    "\n",
    "Entités qui font partie du champ d'étude du datasprint : \n",
    "- 27 ports identifiés par leurs ughs_id \n",
    "- 7 bureaux des Fermes \n",
    "- 1 direction des Fermes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_coocurrences_graph_sprint_colored(data, key_1, key_2, params=None):\n",
    "    # créer un graphe\n",
    "    Graph = nx.Graph()\n",
    "\n",
    "    # créer des dict pour les deux types de noeuds et les liens\n",
    "    key1_uniq = {}\n",
    "    key2_uniq = {}\n",
    "    edges_uniq = {}\n",
    "    default_params = {\n",
    "        \"color_1\": \"rgb(51, 204, 255)\", # noeuds de type 1 en bleu clair\n",
    "        \"color_2\": \"rgb(238, 130, 238)\", # noeuds de type 2 en rose\n",
    "        \"node_min_size\": 1,\n",
    "        \"node_max_size\": 10\n",
    "    }\n",
    "    final_params = default_params\n",
    "    if params is not None :\n",
    "        final_params = {\n",
    "            *default_params,\n",
    "            *params\n",
    "        }\n",
    "        \n",
    "    # colorer les ports / ou autres entités rattachées à la direction des fermes de La Rochelle (au sprint)\n",
    "    # en bleu si entité de départ\n",
    "    # en violet si entité d'arrivée\n",
    "    sprint_ughs_id = ['A1964694','A0171758','A0136930','A0196496','A0198999','A0137148','A0127055','A0133403','A0213721','A0199508','A0148208','A0141325','A0138533','A1964982','A0186515','A0124809','A1964767','A0172590','A0181608','A0165077','A0169240','A0165056','A1963997','A0136403','A0195938','A0122971','A0207992']\n",
    "    sprint_bureaux = ['Alligre', 'Saint-Martin île de Ré', 'Marennes', 'Rochefort', 'Charente', 'La Rochelle', 'Sables-d\\'Olonne']\n",
    "    sprint_direction = 'La Rochelle'\n",
    "    \n",
    "    # choisir par rapport à quelles valeurs on va filtrer la coloration bleue, en fonction des keys données en argument\n",
    "    chosen_filter1 = None\n",
    "    if key_1 == 'departure_fr':\n",
    "        chosen_filter1 = sprint_ughs_id\n",
    "    elif key_1 == 'departure_ferme_bureau':\n",
    "        chosen_filter1 = sprint_bureaux\n",
    "    elif key_1 == 'departure_ferme_direction':\n",
    "        chosen_filter1 = sprint_direction \n",
    "    \n",
    "    # choisir par rapport à quelles valeurs on va filtrer la coloration violette, en fonction des keys données en argument\n",
    "    chosen_filter2 = None\n",
    "    if key_2 == 'destination_fr':\n",
    "        chosen_filter2 = sprint_ughs_id\n",
    "    elif key_2 == 'destination_ferme_bureau':\n",
    "        chosen_filter2 = sprint_bureaux\n",
    "    elif key_2 == 'destination_ferme_direction':\n",
    "        chosen_filter2 = sprint_direction \n",
    "    \n",
    "    # remplir les dicts\n",
    "    for datum in data:\n",
    "    \n",
    "        if key_1 in datum and key_2 in datum:\n",
    "            value_1 = datum[key_1] if datum[key_1] is not None else \"undefined\"\n",
    "            value_2 = datum[key_2] if datum[key_2] is not None else \"undefined\"\n",
    "            value_1_id = key_1 + \"_\" + value_1\n",
    "            value_2_id = key_2 + \"_\" + value_2\n",
    "            \n",
    "            # on changera la variable color attribuée au noeud s'il passe le filtre de rattachement au sprint\n",
    "            color = final_params[\"color_1\"]\n",
    "        \n",
    "            if value_1_id in key1_uniq:\n",
    "                key1_uniq[value_1_id] = {**key1_uniq[value_1_id], \"size\": key1_uniq[value_1_id][\"size\"] + 1}\n",
    "            else:\n",
    "                # coloration en bleu si le noeud se rattache à la direction des fermes de La Rochelle\n",
    "                if (chosen_filter1 == sprint_ughs_id and datum['departure_uhgs_id'] is not None and datum['departure_uhgs_id'] in sprint_ughs_id):\n",
    "                    color = \"rgb (0, 0, 255)\"\n",
    "                elif (chosen_filter1 == sprint_bureaux and datum['departure_ferme_bureau'] is not None and datum['departure_ferme_bureau'] in sprint_bureaux):\n",
    "                    color = \"rgb (0, 0, 255)\"\n",
    "                elif (chosen_filter1 == sprint_direction and datum['departure_ferme_direction'] is not None and datum['departure_ferme_direction'] in sprint_direction) :\n",
    "                    color = \"rgb (0, 0, 255)\"\n",
    "                    \n",
    "                key1_uniq[value_1_id] = {\n",
    "                   \"type\": key_1, \n",
    "                   \"name\": value_1, \n",
    "                   \"color\": color,\n",
    "                   \"size\": 1\n",
    "                }\n",
    "            \n",
    "            # on changera la variable color attribuée au noeud s'il passe le filtre de rattachement au sprint\n",
    "            color = final_params[\"color_2\"]\n",
    "            \n",
    "            if value_2_id in key2_uniq:\n",
    "                key2_uniq[value_2_id] = {**key2_uniq[value_2_id], \"size\": key2_uniq[value_2_id][\"size\"] + 1}\n",
    "            else:\n",
    "                # coloration en violet si le noeud se rattache à la direction des fermes de La Rochelle\n",
    "                if (chosen_filter2 == sprint_ughs_id and datum['destination_uhgs_id'] is not None and datum['destination_uhgs_id'] in sprint_ughs_id):\n",
    "                    color = \"rgb(70, 0, 128)\"\n",
    "                elif (chosen_filter2 == sprint_bureaux and datum['destination_ferme_bureau'] is not None and datum['destination_ferme_bureau'] in sprint_bureaux):\n",
    "                    color = \"rgb(70, 0, 128)\"\n",
    "                elif (chosen_filter2 == sprint_direction and datum['destination_ferme_direction'] is not None and datum['destination_ferme_direction'] in sprint_direction) :\n",
    "                    color = \"rgb(70, 0, 128)\"\n",
    "                    \n",
    "                key2_uniq[value_2_id] = {\n",
    "                   \"type\": key_2, \n",
    "                   \"name\": value_2, \n",
    "                   \"color\": color,\n",
    "                   \"size\": 1\n",
    "               }\n",
    "                \n",
    "            edge_footprint = value_1_id + \"-\" + value_2_id\n",
    "            if edge_footprint in edges_uniq:\n",
    "                edges_uniq[edge_footprint][\"weight\"] += 1\n",
    "            else:\n",
    "                edges_uniq[edge_footprint] = {\n",
    "                    \"source\": value_1_id,\n",
    "                    \"target\": value_2_id,\n",
    "                    \"weight\": 1\n",
    "                }\n",
    "    # concaténer les deux dicts de noeuds en un seul\n",
    "    all_nodes = key1_uniq\n",
    "    all_nodes.update(key2_uniq)\n",
    "    # applatir et formatter les noeuds\n",
    "    nodes = []\n",
    "    for key, node in all_nodes.items():\n",
    "        nodes.append((key, node))\n",
    "    edges = []\n",
    "\n",
    "    for key, edge in edges_uniq.items():\n",
    "        edges.append((edge[\"source\"], edge[\"target\"], {\"weight\": edge[\"weight\"]}))\n",
    "        \n",
    "    # ajuster la taille des noeuds en fonction d'un min et d'un max donnés\n",
    "    domain_min_nodes_size = min([node[1]['size'] for node in nodes])\n",
    "    domain_max_nodes_size = max([node[1]['size'] for node in nodes])\n",
    "    range_in_nodes_size = [final_params[\"node_min_size\"], final_params[\"node_max_size\"]]\n",
    "    nodes_size_mapping_params = [domain_min_nodes_size, domain_max_nodes_size, *range_in_nodes_size]\n",
    "\n",
    "    for node in nodes:\n",
    "        node[1][\"size\"] = map_value(node[1][\"size\"], *nodes_size_mapping_params)\n",
    "        node[1][\"label\"] = node[1][\"name\"]\n",
    "\n",
    "\n",
    "    Graph.add_nodes_from(nodes)\n",
    "    Graph.add_edges_from(edges)\n",
    "\n",
    "    return Sigma(Graph, start_layout=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_coocurrences_graph_sprint_colored(flows_with_toflit_partners, 'departure_ferme_bureau', 'destination_fr_as_toflit_partner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_coocurrences_graph_sprint_filtered(data, key_1, key_2, params=None):\n",
    "    \n",
    "    # créer un graphe\n",
    "    Graph = nx.Graph()\n",
    "\n",
    "    # créer des dict pour les deux types de noeuds et les liens\n",
    "    key1_uniq = {}\n",
    "    key2_uniq = {}\n",
    "    edges_uniq = {}\n",
    "    default_params = {\n",
    "        \"color_1\": \"rgb(0, 0, 255)\", # noeuds de type 1 en bleu foncé\n",
    "        \"color_2\": \"rgb(70, 0, 128)\",# noeuds de type 2 en violet foncé \n",
    "        \"node_min_size\": 1,\n",
    "        \"node_max_size\": 10\n",
    "    }\n",
    "    final_params = default_params\n",
    "    if params is not None :\n",
    "        final_params = {\n",
    "            *default_params,\n",
    "            *params\n",
    "        }\n",
    "        \n",
    "    # filtrer les ports / ou autres entités rattachées à la direction des fermes de La Rochelle (au sprint)\n",
    "    sprint_ughs_id = ['A1964694','A0171758','A0136930','A0196496','A0198999','A0137148','A0127055','A0133403','A0213721','A0199508','A0148208','A0141325','A0138533','A1964982','A0186515','A0124809','A1964767','A0172590','A0181608','A0165077','A0169240','A0165056','A1963997','A0136403','A0195938','A0122971','A0207992']\n",
    "    sprint_bureaux = ['Alligre', 'Saint-Martin île de Ré', 'Marennes', 'Rochefort', 'Charente', 'La Rochelle', 'Sables-d\\'Olonne']\n",
    "    sprint_direction = 'La Rochelle'\n",
    "    \n",
    "    # choisir par rapport à quelles valeurs on va filtrer, en fonction des keys données en argument\n",
    "    chosen_filter1 = None\n",
    "    if key_1 == 'departure_fr':\n",
    "        chosen_filter1 = sprint_ughs_id\n",
    "    elif key_1 == 'departure_ferme_bureau':\n",
    "        chosen_filter1 = sprint_bureaux\n",
    "    elif key_1 == 'departure_ferme_direction':\n",
    "        chosen_filter1 = sprint_direction \n",
    "    \n",
    "    # choisir par rapport à quelles valeurs on va filtrer la coloration violette, en fonction des keys données en argument\n",
    "    chosen_filter2 = None\n",
    "    if key_2 == 'destination_fr':\n",
    "        chosen_filter2 = sprint_ughs_id\n",
    "    elif key_2 == 'destination_ferme_bureau':\n",
    "        chosen_filter2 = sprint_bureaux\n",
    "    elif key_2 == 'destination_ferme_direction':\n",
    "        chosen_filter2 = sprint_direction \n",
    "    \n",
    "    # remplir les dicts\n",
    "    for datum in data:\n",
    "    \n",
    "        if key_1 in datum and key_2 in datum:\n",
    "            value_1 = datum[key_1] if datum[key_1] is not None else \"undefined\"\n",
    "            value_2 = datum[key_2] if datum[key_2] is not None else \"undefined\"\n",
    "            value_1_id = key_1 + \"_\" + value_1\n",
    "            value_2_id = key_2 + \"_\" + value_2\n",
    "            \n",
    "            # on n'ajoutera les noeuds et le lien entre eux que s'ils passent le filtre de rattachement au sprint\n",
    "            valid_node_1 = False\n",
    "            valid_node_2 = False\n",
    "            if (chosen_filter1 == sprint_ughs_id and datum['departure_uhgs_id'] is not None and datum['departure_uhgs_id'] in sprint_ughs_id):\n",
    "                valid_node_1 = True\n",
    "            elif (chosen_filter1 == sprint_bureaux and datum['departure_ferme_bureau'] is not None and datum['departure_ferme_bureau'] in sprint_bureaux):\n",
    "                valid_node_1 = True\n",
    "            elif (chosen_filter1 == sprint_direction and datum['departure_ferme_direction'] is not None and datum['departure_ferme_direction'] in sprint_direction) :\n",
    "                valid_node_1 = True\n",
    "            if (chosen_filter2 == sprint_ughs_id and datum['destination_uhgs_id'] is not None and datum['destination_uhgs_id'] in sprint_ughs_id):\n",
    "                valid_node_2 = True\n",
    "            elif (chosen_filter2 == sprint_bureaux and datum['destination_ferme_bureau'] is not None and datum['destination_ferme_bureau'] in sprint_bureaux):\n",
    "                valid_node_2 = True\n",
    "            elif (chosen_filter2 == sprint_direction and datum['destination_ferme_direction'] is not None and datum['destination_ferme_direction'] in sprint_direction) :\n",
    "                valid_node_2 = True\n",
    "            \n",
    "            if valid_node_1 and valid_node_2:\n",
    "                \n",
    "                if value_1_id in key1_uniq:\n",
    "                    key1_uniq[value_1_id] = {**key1_uniq[value_1_id], \"size\": key1_uniq[value_1_id][\"size\"] + 1}\n",
    "                else:\n",
    "                    key1_uniq[value_1_id] = {\n",
    "                       \"type\": key_1, \n",
    "                       \"name\": value_1, \n",
    "                       \"color\": final_params['color_1'],\n",
    "                       \"size\": 1\n",
    "                    }\n",
    "\n",
    "                if value_2_id in key2_uniq:\n",
    "                    key2_uniq[value_2_id] = {**key2_uniq[value_2_id], \"size\": key2_uniq[value_2_id][\"size\"] + 1}\n",
    "                else:\n",
    "                    key2_uniq[value_2_id] = {\n",
    "                       \"type\": key_2, \n",
    "                       \"name\": value_2, \n",
    "                       \"color\": final_params['color_2'],\n",
    "                       \"size\": 1\n",
    "                    }\n",
    "\n",
    "                edge_footprint = value_1_id + \"-\" + value_2_id\n",
    "                if edge_footprint in edges_uniq:\n",
    "                    edges_uniq[edge_footprint][\"weight\"] += 1\n",
    "                else:\n",
    "                    edges_uniq[edge_footprint] = {\n",
    "                        \"source\": value_1_id,\n",
    "                        \"target\": value_2_id,\n",
    "                        \"weight\": 1\n",
    "                    }\n",
    "                    \n",
    "    # concaténer les deux dicts de noeuds en un seul\n",
    "    all_nodes = key1_uniq\n",
    "    all_nodes.update(key2_uniq)\n",
    "    # applatir et formatter les noeuds\n",
    "    nodes = []\n",
    "    for key, node in all_nodes.items():\n",
    "        nodes.append((key, node))\n",
    "    edges = []\n",
    "\n",
    "    for key, edge in edges_uniq.items():\n",
    "        edges.append((edge[\"source\"], edge[\"target\"], {\"weight\": edge[\"weight\"]}))\n",
    "        \n",
    "    # ajuster la taille des noeuds en fonction d'un min et d'un max donnés\n",
    "    domain_min_nodes_size = min([node[1]['size'] for node in nodes])\n",
    "    domain_max_nodes_size = max([node[1]['size'] for node in nodes])\n",
    "    range_in_nodes_size = [final_params[\"node_min_size\"], final_params[\"node_max_size\"]]\n",
    "    nodes_size_mapping_params = [domain_min_nodes_size, domain_max_nodes_size, *range_in_nodes_size]\n",
    "\n",
    "    for node in nodes:\n",
    "        node[1][\"size\"] = map_value(node[1][\"size\"], *nodes_size_mapping_params)\n",
    "        node[1][\"label\"] = node[1][\"name\"]\n",
    "\n",
    "\n",
    "    Graph.add_nodes_from(nodes)\n",
    "    Graph.add_edges_from(edges)\n",
    "\n",
    "    return Sigma(Graph, start_layout=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_coocurrences_graph_sprint_filtered(flows_datasprint, 'departure_fr','destination_fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from poitousprint import Portic, Toflit\n",
    "import json\n",
    "import networkx as nx\n",
    "from ipysigma import Sigma\n",
    "\n",
    "portic_client = Portic()\n",
    "toflit_client = Toflit()\n",
    "\n",
    "# this function allows to map a value from a domain of min-max to another\n",
    "def map_value(value, domain_min, domain_max, range_min, range_max):\n",
    "    left_span = domain_max - domain_min\n",
    "    right_span = range_max - range_min\n",
    "\n",
    "    # Convert the left range into a 0-1 range (float)\n",
    "    scaled = float(value - domain_min) / float(left_span)\n",
    "\n",
    "    # Convert the 0-1 range into a value in the right range.\n",
    "    return range_min + (scaled * right_span)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonction générique qui permet de fabriquer un réseau à partir :\n",
    "\n",
    "1. d'une liste de dicts (ex. flux toflit18)\n",
    "2. d'une liste de deux propriétés à comparer\n",
    "3. d'un param filter_import_export que l'on peut mettre sur import ou exports (par défaut on a à la fois les imports et les exports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_coocurrences_graph(data, key_1, key_2, filter_export_import=None, params=None):\n",
    "    if filter_export_import not in [None, 'Exports', 'Imports']:\n",
    "        print(\"filter_export_import must be 'Exports', 'Imports' or None\")\n",
    "        raise\n",
    "    \n",
    "    # créer un graphe\n",
    "    Graph = nx.Graph()\n",
    "\n",
    "    # créer des dict pour les deux types de noeuds et les liens\n",
    "    key1_uniq = {}\n",
    "    key2_uniq = {}\n",
    "    edges_uniq = {}\n",
    "    default_params = {\n",
    "        \"color_1\": \"rgb(0, 255, 0)\",\n",
    "        \"color_2\": \"rgb(255, 0, 0)\",\n",
    "        \"node_min_size\": 1,\n",
    "        \"node_max_size\": 10\n",
    "    }\n",
    "    final_params = default_params\n",
    "    if params is not None :\n",
    "        final_params = {\n",
    "            *default_params,\n",
    "            *params\n",
    "        }\n",
    "    \n",
    "    # remplir les dicts\n",
    "    for datum in data:\n",
    "        if (filter_export_import is not None and datum['export_import'] != filter_export_import):\n",
    "            continue\n",
    "            \n",
    "        if key_1 in datum and key_2 in datum:\n",
    "            value_1 = datum[key_1] if datum[key_1] is not None else \"undefined\"\n",
    "            value_2 = datum[key_2] if datum[key_2] is not None else \"undefined\"\n",
    "            value_1_id = key_1 + \"_\" + value_1\n",
    "            value_2_id = key_2 + \"_\" + value_2\n",
    "            \n",
    "            if value_1_id in key1_uniq:\n",
    "                key1_uniq[value_1_id] = {**key1_uniq[value_1_id], \"size\": key1_uniq[value_1_id][\"size\"] + 1}\n",
    "            else:\n",
    "               key1_uniq[value_1_id] = {\n",
    "                   \"type\": key_1, \n",
    "                   \"name\": value_1, \n",
    "                   \"color\": final_params[\"color_1\"],\n",
    "                   \"size\": 1\n",
    "               }\n",
    "            \n",
    "            if value_2_id in key2_uniq:\n",
    "                key2_uniq[value_2_id] = {**key2_uniq[value_2_id], \"size\": key2_uniq[value_2_id][\"size\"] + 1}\n",
    "            else:\n",
    "               key2_uniq[value_2_id] = {\n",
    "                   \"type\": key_2, \n",
    "                   \"name\": value_2, \n",
    "                   \"color\": final_params[\"color_2\"],\n",
    "                   \"size\": 1\n",
    "               }\n",
    "            \n",
    "            edge_footprint = value_1_id + \"-\" + value_2_id\n",
    "            if edge_footprint in edges_uniq:\n",
    "                edges_uniq[edge_footprint][\"weight\"] += 1\n",
    "            else:\n",
    "                edges_uniq[edge_footprint] = {\n",
    "                    \"source\": value_1_id,\n",
    "                    \"target\": value_2_id,\n",
    "                    \"weight\": 1\n",
    "                }\n",
    "                \n",
    "    # concaténer les deux dicts de noeuds en un seul\n",
    "    all_nodes = key1_uniq\n",
    "    all_nodes.update(key2_uniq)\n",
    "    # applatir et formatter les noeuds\n",
    "    nodes = []\n",
    "    for key, node in all_nodes.items():\n",
    "        nodes.append((key, node))\n",
    "    edges = []\n",
    "\n",
    "    for key, edge in edges_uniq.items():\n",
    "        edges.append((edge[\"source\"], edge[\"target\"], {\"weight\": edge[\"weight\"]}))\n",
    "        \n",
    "    # ajuster la taille des noeuds en fonction d'un min et d'un max donnés\n",
    "    domain_min_nodes_size = min([node[1]['size'] for node in nodes])\n",
    "    domain_max_nodes_size = max([node[1]['size'] for node in nodes])\n",
    "    range_in_nodes_size = [final_params[\"node_min_size\"], final_params[\"node_max_size\"]]\n",
    "    nodes_size_mapping_params = [domain_min_nodes_size, domain_max_nodes_size, *range_in_nodes_size]\n",
    "\n",
    "    for node in nodes:\n",
    "        node[1][\"size\"] = map_value(node[1][\"size\"], *nodes_size_mapping_params)\n",
    "        node[1][\"label\"] = node[1][\"name\"]\n",
    "\n",
    "\n",
    "    Graph.add_nodes_from(nodes)\n",
    "    Graph.add_edges_from(edges)\n",
    "\n",
    "    return Sigma(Graph, start_layout=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Je vais chercher les flux du sprint (côté Toflit) pour nourrir mes réseaux\n",
    "\n",
    "nb : pour les flux concernant le sprint on n'a qu'une seule direction des Fermes : La Rochelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# je vais chercher les flux qui concernent le sprint côté Toflit\n",
    "\n",
    "flows = toflit_client.get_flows(\n",
    "    year=1789,\n",
    "    customs_region='La Rochelle', \n",
    "    params=[\n",
    "      \"product_revolutionempire\",\n",
    "      \"partner\",\n",
    "      \"export_import\",\n",
    "      \"value\",\n",
    "      \"line\",\n",
    "      \"partner_simplification\",\n",
    "      \"customs_office\",\n",
    "      \"customs_region\"\n",
    "\t]\n",
    ")\n",
    "flows[0]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(flows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Réseau bipartite entre les directions des Fermes et les partenaires commerciaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_coocurrences_graph(flows, \"customs_region\", \"partner_simplification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Réseau bipartite entre les bureaux des Fermes et les partenaires commerciaux "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. avec filtre sur les imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_coocurrences_graph(flows, \"customs_office\", \"partner_simplification\", filter_export_import = 'Imports')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. avec filtre sur les exports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_coocurrences_graph(flows, \"customs_office\", \"partner_simplification\", filter_export_import = 'Exports')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Réseau tripartite entre les bureaux des Fermes, les produits et les partenaires commerciaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# je customise la fonction de création de Graphe\n",
    "\n",
    "def render_tripartite_graph(data, key_1, key_2, key_3, filter_export_import=None, params=None):\n",
    "    if filter_export_import not in [None, 'Exports', 'Imports']:\n",
    "        print(\"filter_export_import must be 'Exports', 'Imports' or None\")\n",
    "        raise\n",
    "    \n",
    "    # créer un graphe\n",
    "    Graph = nx.Graph()\n",
    "\n",
    "    # créer des dict pour les deux types de noeuds et les liens\n",
    "    key1_uniq = {} # -> products\n",
    "    key2_uniq = {} # -> partners\n",
    "    key3_uniq = {} # customs->office\n",
    "    edges_uniq = {}\n",
    "    \n",
    "    default_params = {\n",
    "        \"color_1\": \"rgb(0, 255, 0)\", # noeuds de type 1 en vert\n",
    "        \"color_2\": \"rgb(255, 0, 0)\", # noeuds de type 2 en rouge\n",
    "        \"color_3\": \"rgb(0, 0, 255)\", # noeuds de type 3 en bleu\n",
    "        \"node_min_size\": 1,\n",
    "        \"node_max_size\": 10\n",
    "    }\n",
    "    final_params = default_params\n",
    "    if params is not None :\n",
    "        final_params = {\n",
    "            *default_params,\n",
    "            *params\n",
    "        }\n",
    "        \n",
    "    # remplir les dicts\n",
    "    for datum in data:\n",
    "        \n",
    "        if (filter_export_import is not None and datum['export_import'] != filter_export_import):\n",
    "            continue\n",
    "            \n",
    "        if key_1 in datum and key_2 in datum and key_3 in datum:\n",
    "            value_1 = datum[key_1] if datum[key_1] is not None else \"undefined\"\n",
    "            value_2 = datum[key_2] if datum[key_2] is not None else \"undefined\"\n",
    "            value_3 = datum[key_2] if datum[key_2] is not None else \"undefined\"\n",
    "            value_1_id = key_1 + \"_\" + value_1\n",
    "            value_2_id = key_2 + \"_\" + value_2\n",
    "            value_3_id = key_3 + \"_\" + value_3\n",
    "            \n",
    "            if value_1_id in key1_uniq:\n",
    "                key1_uniq[value_1_id] = {**key1_uniq[value_1_id], \"size\": key1_uniq[value_1_id][\"size\"] + 1}\n",
    "            else:\n",
    "               key1_uniq[value_1_id] = {\n",
    "                   \"type\": key_1, \n",
    "                   \"name\": value_1, \n",
    "                   \"color\": final_params[\"color_1\"],\n",
    "                   \"size\": 1\n",
    "               }\n",
    "            if value_2_id in key2_uniq:\n",
    "                key2_uniq[value_2_id] = {**key2_uniq[value_2_id], \"size\": key2_uniq[value_2_id][\"size\"] + 1}\n",
    "            else:\n",
    "               key2_uniq[value_2_id] = {\n",
    "                   \"type\": key_2, \n",
    "                   \"name\": value_2, \n",
    "                   \"color\": final_params[\"color_2\"],\n",
    "                   \"size\": 1\n",
    "               }\n",
    "            if value_3_id in key3_uniq:\n",
    "                key3_uniq[value_3_id] = {**key3_uniq[value_3_id], \"size\": key3_uniq[value_3_id][\"size\"] + 1}\n",
    "            else:\n",
    "               key3_uniq[value_3_id] = {\n",
    "                   \"type\": key_3, \n",
    "                   \"name\": value_3, \n",
    "                   \"color\": final_params[\"color_3\"],\n",
    "                   \"size\": 1\n",
    "               }\n",
    "            \n",
    "            edge_footprints = {\n",
    "                str(value_1_id + \"-\" + value_2_id): {\n",
    "                    'source': value_1_id,\n",
    "                    'target': value_2_id\n",
    "                }, \n",
    "                str(value_2_id + \"-\" + value_3_id): {\n",
    "                    'source': value_2_id,\n",
    "                    'target': value_3_id\n",
    "                }, \n",
    "                str(value_1_id + \"-\" + value_3_id): {\n",
    "                    'source': value_1_id,\n",
    "                    'target': value_3_id\n",
    "                }\n",
    "            } \n",
    "\n",
    "            for edge_footprint in edge_footprints.keys():\n",
    "                if edge_footprint in edges_uniq:\n",
    "                    edges_uniq[edge_footprint][\"weight\"] += 1\n",
    "                else:\n",
    "                    edges_uniq[edge_footprint] = {\n",
    "                        \"source\": edge_footprints[edge_footprint]['source'],\n",
    "                        \"target\": edge_footprints[edge_footprint]['target'],\n",
    "                        \"weight\": 1\n",
    "                    }\n",
    "    # concaténer les deux dicts de noeuds en un seul\n",
    "    all_nodes = key1_uniq\n",
    "    all_nodes.update(key2_uniq)\n",
    "    all_nodes.update(key3_uniq) \n",
    "\n",
    "    # applatir et formatter les noeuds\n",
    "    nodes = []\n",
    "    for key, node in all_nodes.items():\n",
    "        nodes.append((key, node))\n",
    "    edges = []\n",
    "\n",
    "    for key, edge in edges_uniq.items():\n",
    "        edges.append((edge[\"source\"], edge[\"target\"], {\"weight\": edge[\"weight\"]}))\n",
    "\n",
    "    domain_min_nodes_size = min([node[1]['size'] for node in nodes])\n",
    "    domain_max_nodes_size = max([node[1]['size'] for node in nodes])\n",
    "    range_in_nodes_size = [1, 10]\n",
    "    nodes_size_mapping_params = [domain_min_nodes_size, domain_max_nodes_size, *range_in_nodes_size]\n",
    "\n",
    "    for node in nodes:\n",
    "        node[1][\"size\"] = map_value(node[1][\"size\"], *nodes_size_mapping_params)\n",
    "        node[1][\"label\"] = node[1][\"name\"]\n",
    "\n",
    "\n",
    "    Graph.add_nodes_from(nodes)\n",
    "    Graph.add_edges_from(edges)\n",
    "\n",
    "    return Sigma(Graph, start_layout=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. avec filtre sur les imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_tripartite_graph(flows, \"partner\", \"product_revolutionempire\", \"customs_office\", filter_export_import = 'Imports')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. avec filtre sur les exports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_tripartite_graph(flows, \"partner\", \"product_revolutionempire\", \"customs_office\", filter_export_import = 'Exports')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
