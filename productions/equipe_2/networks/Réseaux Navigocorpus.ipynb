{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60e5eb41",
   "metadata": {},
   "source": [
    "# Réseaux Navigocorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "652b8d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import networkx as nx\n",
    "from poitousprint import Portic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2222aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "INNER_ADMIRALTIES = {'La Rochelle', 'Marennes', 'Sables-d’Olonne'}\n",
    "INNER_PROVINCES = {'Aunis', 'Poitou', 'Saintonge'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdffe872",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Portic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d5b765a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ancienne méthode\n",
    "# flows = client.get_flows(year=1789, source_subset='Poitou_1789')\n",
    "# flows = [flow for flow in flows if flow['departure_action'] == 'Out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16413cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# En utilisant les données ajustées\n",
    "with open('./resources/flows.csv') as f:\n",
    "    flows = list(csv.DictReader(f))\n",
    "    \n",
    "    for f in flows:\n",
    "        f['departure'] = f['port_depart']\n",
    "        f['destination'] = f['port_destination']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2096847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[1-20]', '[21-50]', '[51-100]', '[101-200]', '[201-500]', '[501 et plus]']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPLITTER = re.compile(r'\\s*(?:et|-)')\n",
    "tonnage_classes = sorted(set(flow['tonnage_class'] for flow in flows if flow['tonnage_class']), key=lambda x: int(SPLITTER.split(x[1:])[0]))\n",
    "tonnage_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6eab78",
   "metadata": {},
   "source": [
    "## Réseau macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1949e722",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph(name, tonnage_class=None, inner=False):\n",
    "    graph = nx.DiGraph()\n",
    "\n",
    "    def add_node(g, name, admiralty=None, peche=0):\n",
    "        if admiralty is None:\n",
    "            admiralty = 'n/a'\n",
    "\n",
    "        if g.has_node(name):\n",
    "            g.nodes[name]['peche'] += peche\n",
    "        else:\n",
    "            g.add_node(\n",
    "                name,\n",
    "                admiralty=admiralty,\n",
    "                peche=peche,\n",
    "                in_region=admiralty in INNER_ADMIRALTIES,\n",
    "                inside_degree=0,\n",
    "                outside_degree=0\n",
    "            )\n",
    "\n",
    "    def add_edge(g, source, target, tonnage):\n",
    "        if g.has_edge(source, target):\n",
    "            attr = g[source][target]\n",
    "            attr['weight'] += 1\n",
    "            attr['tonnage'] += tonnage\n",
    "        else:\n",
    "            g.add_edge(\n",
    "                source,\n",
    "                target,\n",
    "                weight=1,\n",
    "                tonnage=tonnage\n",
    "            )\n",
    "\n",
    "    for flow in flows:\n",
    "        if tonnage_class is not None and flow['tonnage_class'] != tonnage_class:\n",
    "            continue\n",
    "        \n",
    "        source = flow['departure']\n",
    "        target = flow['destination']\n",
    "\n",
    "        source_admiralty = flow['departure_admiralty']\n",
    "        target_admiralty = flow['destination_admiralty']\n",
    "        \n",
    "        tonnage = 0\n",
    "\n",
    "        try:\n",
    "            tonnage = int(flow['tonnage'])\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "        inside_flow = source_admiralty in INNER_ADMIRALTIES and target_admiralty in INNER_ADMIRALTIES\n",
    "        \n",
    "        if inner and not inside_flow:\n",
    "            continue\n",
    "\n",
    "        # Macro graph\n",
    "        if source == target:\n",
    "            add_node(graph, source, source_admiralty, 1)\n",
    "        else:\n",
    "            add_node(graph, source, source_admiralty)\n",
    "            add_node(graph, target, target_admiralty)\n",
    "            add_edge(graph, source, target, tonnage)\n",
    "\n",
    "            if source_admiralty in INNER_ADMIRALTIES:\n",
    "                if inside_flow:\n",
    "                    graph.nodes[source]['inside_degree'] += 1\n",
    "                else:\n",
    "                    graph.nodes[source]['outside_degree'] += 1\n",
    "    \n",
    "    nx.write_gexf(graph, './outputs/%s.gexf' % name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a002e2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_graph('macro')\n",
    "build_graph('inner', inner=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af1cefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cls in tonnage_classes:\n",
    "    build_graph(cls, tonnage_class=cls)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
